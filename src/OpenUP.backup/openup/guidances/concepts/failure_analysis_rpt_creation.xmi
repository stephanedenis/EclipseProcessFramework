<?xml version="1.0" encoding="UTF-8"?>
<org.eclipse.epf.uma:ContentDescription xmi:version="2.0"
    xmlns:xmi="http://www.omg.org/XMI" xmlns:org.eclipse.epf.uma="http://www.eclipse.org/epf/uma/1.0.4/uma.ecore"
     xmlns:epf="http://www.eclipse.org/epf"
    epf:version="1.2.0" xmi:id="-9gUpkUYqONF3x8UWwAO_zw"
    name="failure_analysis_rpt_creation,_0jhR0MlgEdmt3adZL5Dmdw" guid="-9gUpkUYqONF3x8UWwAO_zw"
    changeDate="2007-05-17T10:00:23.546-0700" version="1.0.0">
  <mainDescription>&lt;h3>&#xD;
    Introduction&#xD;
&lt;/h3>&#xD;
&lt;p>&#xD;
    During testing, you will encounter failures related to the execution of your tests in different forms, such as code&#xD;
    defects, user errors, program malfunctions, and test scripting issues. This&amp;nbsp;concept discusses some ways to conduct&#xD;
    failure analysis and then to report your findings.&#xD;
&lt;/p>&#xD;
&lt;h3>&#xD;
    Failure Analysis&#xD;
&lt;/h3>&#xD;
&lt;p>&#xD;
    After you run the tests, its good practice to identify inputs for review of the results of the testing effort. Some&#xD;
    likely sources are defects that occurred during the execution of test scripts, change request metrics, and&amp;nbsp;&lt;a class=&quot;elementLinkWithType&quot; href=&quot;./../../../openup/workproducts/test_log_CBA2FDF4.html&quot; guid=&quot;_0ZlSsMlgEdmt3adZL5Dmdw&quot;>Artifact: Test Log&lt;/a> details.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    Running test scripts results in errors of different kinds such as uncovered defects, unexpected behavior, or general&#xD;
    failure of the test script to run properly. When you run test scripts, one of the most important things to do is to&#xD;
    distinguish between the causes and effects of failure. It is important to differentiate failures in the system under&#xD;
    test&amp;nbsp;from those related to the tests themselves.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    Change request metrics are useful in analyzing and correcting failures in the testing. Select metrics that will&#xD;
    facilitate creation of incident reports from a collection of change requests.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    Change request metrics that you may find useful in your failure analysis include:&#xD;
&lt;/p>&#xD;
&lt;ul>&#xD;
    &lt;li>&#xD;
        test coverage&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        priority&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        impact&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        defect trends&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        density&#xD;
    &lt;/li>&#xD;
&lt;/ul>&#xD;
&lt;p>&#xD;
    Finally, one of the most critical sources of your failure analysis is the&amp;nbsp;&lt;a class=&quot;elementLinkWithType&quot; href=&quot;./../../../openup/workproducts/test_log_CBA2FDF4.html&quot; guid=&quot;_0ZlSsMlgEdmt3adZL5Dmdw&quot;>Artifact: Test Log&lt;/a>.&#xD;
    Relevant logs might come from many sources: they might be captured by the tools you use (both test execution and&#xD;
    diagnostic tools), generated by automated tests or metrics tools, output from the target test items themselves, or&#xD;
    recorded manually by the tester. Gather all of the available test log sources and examine their content. Check that all&#xD;
    the scheduled testing executed to completion, and that all the needed tests&amp;nbsp;have been scheduled.&#xD;
&lt;/p>&#xD;
&lt;h3>&#xD;
    Self-Documenting Tests&#xD;
&lt;/h3>&#xD;
&lt;p>&#xD;
    For automated tests, its important for the&amp;nbsp;test itself to examine the results and clearly report itself as passing&#xD;
    or failing. This provides the most efficient way to run a suite of tests without the need for human intervention. When&#xD;
    authoring self-documenting tests, ensure that the reporting considers both passing and failing results.&#xD;
&lt;/p>&#xD;
&lt;h3>&#xD;
    Recording Your Findings&#xD;
&lt;/h3>&#xD;
&lt;p>&#xD;
    Once you have conducted your failure analysis, you might decide to formalize the results of this analysis by recording&#xD;
    your findings in a report. There are several factors that go into deciding whether to record your failure analysis in a&#xD;
    report. Some of the key factors include: level of testing formality, complexity of the testing effort, and the need to&#xD;
    communicate the testing results to the entire development team. In less formal environments, it may be sufficient to&#xD;
    record your failure analysis in&amp;nbsp;a summary fashion.&#xD;
&lt;/p></mainDescription>
</org.eclipse.epf.uma:ContentDescription>
